{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f42546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pblo2\\AppData\\Local\\Temp\\ipykernel_75860\\2472609794.py:74: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  return s.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SP500\n",
      "date                \n",
      "2025-08-08  0.024277\n",
      "2025-08-15  0.009445\n",
      "2025-08-22  0.002653\n",
      "2025-08-29 -0.001028\n",
      "2025-09-05  0.000000\n",
      "            FEDFUNDS\n",
      "date                \n",
      "2025-04-30      4.33\n",
      "2025-05-31      4.33\n",
      "2025-06-30      4.33\n",
      "2025-07-31      4.33\n",
      "2025-08-31      4.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pblo2\\AppData\\Local\\Temp\\ipykernel_75860\\2472609794.py:68: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  return getattr(s.resample(freq), agg)()\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Literal, Dict, Any, List, Union, Number    \n",
    "\n",
    "#Motor API FRED -> pd.DataFrame sucio\n",
    "#Entrada: api_key, endpoint y diccionario \n",
    "#Out: DataFrame sucio\n",
    "\n",
    "class DataLoad:\n",
    "    def __init__(self, api_key=\"02ea49012ba021ea89f1110c48de7380\", timeout=20, retries=3, backoff=1.7):\n",
    "        self.api_key = api_key                    # <- corregido (antes apy_key)\n",
    "        self.timeout = timeout\n",
    "        self.retries = retries\n",
    "        self.backoff = backoff                    # <- guardado (antes faltaba)\n",
    "        self.url = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "\n",
    "    def DicSerie(self, *, id: str, freq_origin: str, freq_objetivo: str,\n",
    "                 agg: str = \"last\", transform: str | None = None, fill: str | None = None) -> dict:\n",
    "        return {\n",
    "            \"id\": id,\n",
    "            \"freq_origin\": freq_origin,     # informativo\n",
    "            \"freq_objetivo\": freq_objetivo, # ej. \"M\", \"W-FRI\"\n",
    "            \"agg\": agg,                     # \"last\",\"mean\",...\n",
    "            \"transform\": transform,         # \"pct_change\",\"yoy_pct\", None\n",
    "            \"fill\": fill,                   # \"ffill\" o None\n",
    "        }\n",
    "\n",
    "    def request_observations(self, series_id: str, **extra_params) -> Dict[str, Any]:\n",
    "        params = {\n",
    "            \"series_id\": series_id,\n",
    "            \"api_key\": self.api_key,        # <- corregido\n",
    "            \"file_type\": \"json\",\n",
    "        }\n",
    "        # agrega sólo los que no son None (ej. observation_start, observation_end)\n",
    "        params.update({k: v for k, v in extra_params.items() if v is not None})\n",
    "\n",
    "        last_err = None\n",
    "        for attempt in range(1, self.retries + 1):\n",
    "            try:\n",
    "                resp = requests.get(self.url, params=params, timeout=self.timeout)\n",
    "                if 200 <= resp.status_code < 300:\n",
    "                    return resp.json()\n",
    "                last_err = f\"HTTP {resp.status_code}: {resp.text[:200]}\"\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "            time.sleep(self.backoff * attempt)\n",
    "\n",
    "        raise RuntimeError(f\"Fallo API FRED [{series_id}]: {last_err}\")\n",
    "\n",
    "    def _to_frame(self, payload: dict) -> pd.DataFrame:\n",
    "        # observations es una lista de dicts con {'date': 'YYYY-MM-DD', 'value': '...'}\n",
    "        obs = payload.get(\"observations\", [])\n",
    "        df = pd.DataFrame(obs)\n",
    "        if df.empty:\n",
    "            return df\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "        return df.set_index(\"date\")[[\"value\"]].sort_index()\n",
    "\n",
    "\n",
    "    def get_one(self, cfg_or_id, *, observation_start: str | None = None, observation_end: str | None = None) -> pd.DataFrame:\n",
    "        # Acepta dict (con 'id') o un string directamente\n",
    "        if isinstance(cfg_or_id, dict):\n",
    "            series_id = cfg_or_id[\"id\"]\n",
    "        else:\n",
    "            series_id = str(cfg_or_id)\n",
    "\n",
    "        raw = self.request_observations(\n",
    "                series_id,\n",
    "                observation_start=observation_start,\n",
    "                observation_end=observation_end,\n",
    "            )\n",
    "        df = self._to_frame(raw)  # <-- devuelve df con índice 'date' y col 'value'\n",
    "            # NADA de fill/resample/transform aquí\n",
    "        return df.rename(columns={\"value\": series_id})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TransformStep:\n",
    "\n",
    "    fn: str\n",
    "    arg: dict[str, any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class SeriesSpec:\n",
    "    fred_id: str\n",
    "    alias: Optional[str] = None\n",
    "    units: Optional[str] = None          # normalize_units (pp, %, bp, rebase, log)\n",
    "    freq_objetivo: str = \"M\"\n",
    "    agg: Literal[\"last\",\"mean\"] = \"last\"\n",
    "    fill: Optional[Literal[\"ffill\",\"bfill\",\"both\"]] = \"ffill\"\n",
    "    steps: List[TransformStep] = field(default_factory=list)  # pipeline ordenado\n",
    "\n",
    "@dataclass\n",
    "class LayerSpec:\n",
    "    name: str\n",
    "    series: List[SeriesSpec]\n",
    "    target_freq: str = \"M\"\n",
    "    resample_agg: Literal[\"last\",\"mean\"] = \"last\"\n",
    "    how_merge: Literal[\"outer\",\"inner\",\"asof\"] = \"outer\"\n",
    "    default_fill: Optional[Literal[\"ffill\",\"bfill\",\"both\"]] = \"ffill\"\n",
    "    derived: List[TransformStep] = field(default_factory=list)\n",
    "    post: List[TransformStep] = field(default_factory=list)\n",
    "\n",
    "#Entry: DataFrame dirty\n",
    "#Exit: DataFrame fill, resample (if is necesary), derivate, z-score, mean\n",
    "\n",
    "Number = Union[int, float, np.number]\n",
    "\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Conjunto de transformaciones/limpieza para `pd.Series` (time series).\n",
    "    Todas las funciones preservan el índice de la serie y son null-safe.\n",
    "    \"\"\"\n",
    "\n",
    "    # 🔴 LIMPIEZA -------------------------------------------------------------\n",
    "\n",
    "    def maybe_fill(self, s: pd.Series, fill: Optional[Literal[\"ffill\", \"bfill\", \"both\"]] = None) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Aplica forward/backward fill si se indica.\n",
    "        fill:\n",
    "          - None   : no hace nada\n",
    "          - \"ffill\": forward fill\n",
    "          - \"bfill\": backward fill\n",
    "          - \"both\" : primero ffill y luego bfill\n",
    "        \"\"\"\n",
    "        if fill is None:\n",
    "            return s\n",
    "        if fill == \"ffill\":\n",
    "            return s.ffill()\n",
    "        if fill == \"bfill\":\n",
    "            return s.bfill()\n",
    "        if fill == \"both\":\n",
    "            return s.ffill().bfill()\n",
    "        raise ValueError(f\"Fill no soportado: {fill}\")\n",
    "\n",
    "    def dropna(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Elimina valores nulos.\"\"\"\n",
    "        return s.dropna()\n",
    "\n",
    "    def clip(self, s: pd.Series, clip_lower: Optional[int] = None, clip_upper: Optional[int] = None) -> pd.Series:\n",
    "        \"\"\"Recorta valores fuera de rango.\"\"\"\n",
    "        return s.clip(lower=clip_lower, upper=clip_upper)\n",
    "\n",
    "    def winsorize(\n",
    "        self,\n",
    "        s: pd.Series,\n",
    "        percentile_low: float = 0.01,\n",
    "        percentile_up: float = 0.99,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Limita outliers por percentiles (winsorización).\n",
    "        \"\"\"\n",
    "        if s.empty:\n",
    "            return s\n",
    "        lo = s.quantile(percentile_low)\n",
    "        hi = s.quantile(percentile_up)\n",
    "        return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "    def normalize_units(self, s: pd.Series, units: str) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Normaliza unidades:\n",
    "        - percent_from_decimal : 0.052 -> 5.2\n",
    "        - decimal_from_percent : 5.2 -> 0.052\n",
    "        - pp_from_decimal      : 0.052 -> 5.2\n",
    "        - pp_from_percent      : 5.2 -> 5.2\n",
    "        - bp_from_percent      : 5.2 -> 520\n",
    "        - bp_from_decimal      : 0.052 -> 520\n",
    "        - percent_from_bp      : 520 -> 5.2\n",
    "        - decimal_from_bp      : 520 -> 0.052\n",
    "        - scale:<factor>       : multiplica por factor (p.ej. \"scale:1e-6\")\n",
    "        - rebase:<base>[@YYYY-MM-DD] : rebasea índices\n",
    "        - log                  : log natural (<=0 → NaN)\n",
    "        - level/identity/none  : identidad\n",
    "        \"\"\"\n",
    "        if s is None or s.empty:\n",
    "            return s\n",
    "\n",
    "        key = (units or \"\").strip().lower()\n",
    "\n",
    "        # Tasas y puntos\n",
    "        if key == \"percent_from_decimal\":\n",
    "            return s * 100.0\n",
    "        if key == \"decimal_from_percent\":\n",
    "            return s / 100.0\n",
    "        if key == \"pp_from_decimal\":\n",
    "            return s * 100.0\n",
    "        if key == \"pp_from_percent\":\n",
    "            return s\n",
    "        if key == \"bp_from_percent\":\n",
    "            return s * 100.0\n",
    "        if key == \"bp_from_decimal\":\n",
    "            return s * 10000.0\n",
    "        if key == \"percent_from_bp\":\n",
    "            return s / 100.0\n",
    "        if key == \"decimal_from_bp\":\n",
    "            return s / 10000.0\n",
    "\n",
    "        # Escalado genérico\n",
    "        if key.startswith(\"scale:\"):\n",
    "            try:\n",
    "                factor = float(key.split(\"scale:\", 1)[1])\n",
    "            except Exception:\n",
    "                raise ValueError(f\"scale:<factor> inválido en '{units}'\")\n",
    "            return s * factor\n",
    "\n",
    "        # Rebase de índices\n",
    "        if key.startswith(\"rebase:\"):\n",
    "            try:\n",
    "                payload = key.split(\"rebase:\", 1)[1]\n",
    "                if \"@\" in payload:\n",
    "                    base_str, date_str = payload.split(\"@\", 1)\n",
    "                    base_val = float(base_str)\n",
    "                    ref_date = pd.to_datetime(date_str)\n",
    "                    ref_val = s.loc[ref_date]\n",
    "                else:\n",
    "                    base_val = float(payload)\n",
    "                    ref_val = s.dropna().iloc[0]\n",
    "            except KeyError:\n",
    "                raise ValueError(f\"No existe dato en la fecha indicada en '{units}'\")\n",
    "            except Exception:\n",
    "                raise ValueError(\"Usa 'rebase:<base>' o 'rebase:<base>@YYYY-MM-DD'\")\n",
    "            return (s / ref_val) * base_val\n",
    "\n",
    "        # Log\n",
    "        if key == \"log\":\n",
    "            s_pos = s.where(s > 0)\n",
    "            return np.log(s_pos)\n",
    "\n",
    "        if key in {\"level\", \"identity\", \"none\", \"\"}:\n",
    "            return s\n",
    "\n",
    "        raise ValueError(f\"Modo de normalize_units no soportado: '{units}'\")\n",
    "\n",
    "    def log(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Log natural (<=0 → NaN).\"\"\"\n",
    "        return np.log(s.where(s > 0))\n",
    "\n",
    "    # 🟠 VARIACIONES ----------------------------------------------------------\n",
    "\n",
    "    def diff(self, s: pd.Series, periods: int = 1) -> pd.Series:\n",
    "        \"\"\"Diferencia simple: s - s.shift(periods).\"\"\"\n",
    "        return s.diff(periods)\n",
    "\n",
    "    def pct_change(self, s: pd.Series, periods: int = 1) -> pd.Series:\n",
    "        \"\"\"Cambio porcentual n-periodos (devuelve en decimales).\"\"\"\n",
    "        return s.pct_change(periods=periods)\n",
    "\n",
    "    def mom(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Atajo de pct_change(1).\"\"\"\n",
    "        return s.pct_change(1)\n",
    "\n",
    "    def yoy(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Interanual (12 períodos).\"\"\"\n",
    "        return s.pct_change(12)\n",
    "\n",
    "    def qoq_annualized(self, s: pd.Series, compounded: bool = True) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Trimestral anualizado:\n",
    "          - compounded=True  → ((1 + pct_change(3))**4 - 1)\n",
    "          - compounded=False → pct_change(3) * 4   (aprox lineal)\n",
    "        \"\"\"\n",
    "        qoq = s.pct_change(3)\n",
    "        if compounded:\n",
    "            return (1.0 + qoq) ** 4 - 1.0\n",
    "        return qoq * 4.0\n",
    "\n",
    "    def rolling_pct_change(self, s: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"Variación acumulada en ventana móvil: s / s.shift(window) - 1.\"\"\"\n",
    "        return s / s.shift(window) - 1.0\n",
    "\n",
    "    # 🟡 TENDENCIA / SUAVIZADO ------------------------------------------------\n",
    "\n",
    "    def rolling_mean(self, s: pd.Series, window: int, min_periods: Optional[int] = None) -> pd.Series:\n",
    "        return s.rolling(window, min_periods=min_periods or window).mean()\n",
    "\n",
    "    def rolling_std(self, s: pd.Series, window: int, min_periods: Optional[int] = None) -> pd.Series:\n",
    "        return s.rolling(window, min_periods=min_periods or window).std()\n",
    "\n",
    "    def ema(self, s: pd.Series, span: int, adjust: bool = False) -> pd.Series:\n",
    "        \"\"\"Media móvil exponencial con ewm(span).\"\"\"\n",
    "        return s.ewm(span=span, adjust=adjust).mean()\n",
    "\n",
    "    def slope(\n",
    "        self,\n",
    "        s: pd.Series,\n",
    "        window: int,\n",
    "        method: Literal[\"diff\", \"ols\"] = \"ols\",\n",
    "        min_periods: Optional[int] = None,\n",
    "        as_annualized: bool = False,\n",
    "        periods_per_year: Optional[int] = None,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Pendiente local en ventana:\n",
    "          - method=\"diff\": s - s.shift(window) (rápido, no escala temporal)\n",
    "          - method=\"ols\" : beta de una regresión y ~ x en cada ventana (x=0..window-1)\n",
    "        as_annualized=True con periods_per_year → multiplica la pendiente.\n",
    "        \"\"\"\n",
    "        mp = min_periods or window\n",
    "        if method == \"diff\":\n",
    "            out = s - s.shift(window)\n",
    "        elif method == \"ols\":\n",
    "            # beta = cov(x,y)/var(x) con x fijo 0..n-1\n",
    "            x = np.arange(window, dtype=float)\n",
    "            x = (x - x.mean())  # centrar para estabilidad\n",
    "            var_x = (x**2).sum()\n",
    "            def _beta(y: np.ndarray) -> float:\n",
    "                if np.isnan(y).any():\n",
    "                    return np.nan\n",
    "                y = y - y.mean()\n",
    "                cov_xy = float((x * y).sum())\n",
    "                return cov_xy / var_x if var_x != 0 else np.nan\n",
    "            out = s.rolling(window, min_periods=mp).apply(_beta, raw=True)\n",
    "        else:\n",
    "            raise ValueError(\"method debe ser 'diff' u 'ols'\")\n",
    "\n",
    "        if as_annualized and periods_per_year:\n",
    "            out = out * periods_per_year\n",
    "        return out\n",
    "\n",
    "    # 🟢 ESTANDARIZACIÓN ------------------------------------------------------\n",
    "\n",
    "    def zscore(self, s: pd.Series, window: Optional[int] = None) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Z-score:\n",
    "          - window=None → (s - mean) / std global\n",
    "          - window=k    → rolling z-score\n",
    "        \"\"\"\n",
    "        if window is None:\n",
    "            return (s - s.mean()) / s.std()\n",
    "        roll = s.rolling(window)\n",
    "        return (s - roll.mean()) / roll.std()\n",
    "\n",
    "    def percentile_rank(self, s: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Ranking percentil 0–1 en ventana (empírico).\n",
    "        Usa rank(pct=True) sobre cada ventana.\n",
    "        \"\"\"\n",
    "        def _pct_rank(x: pd.Series) -> float:\n",
    "            return x.rank(pct=True).iloc[-1]\n",
    "        return s.rolling(window, min_periods=window).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False)\n",
    "\n",
    "    def rebase_index(self, s: pd.Series, base: float = 100.0, ref: Optional[pd.Timestamp] = None) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Rebase sencillo a `base`. Si `ref` es None usa el primer valor no nulo.\n",
    "        \"\"\"\n",
    "        if s.empty:\n",
    "            return s\n",
    "        ref_val = s.loc[ref] if ref is not None else s.dropna().iloc[0]\n",
    "        return (s / ref_val) * base\n",
    "\n",
    "    # 🔵 COMPOSICIÓN INTRA-SERIE ---------------------------------------------\n",
    "\n",
    "    def delta_vs_min(self, s: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"Diferencia vs mínimo rolling.\"\"\"\n",
    "        return s - s.rolling(window).min()\n",
    "\n",
    "    def delta_vs_max(self, s: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"Diferencia vs máximo rolling.\"\"\"\n",
    "        return s - s.rolling(window).max()\n",
    "\n",
    "    def cumulative_sum(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Acumulado (útil en flujos).\"\"\"\n",
    "        return s.cumsum()\n",
    "\n",
    "    def annualize_from_periods(\n",
    "        self,\n",
    "        s_returns: pd.Series,\n",
    "        periods_per_year: int,\n",
    "        compounded: bool = True,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Lleva una tasa/retorno de 'periods_per_year' a anual:\n",
    "          - compounded=True  → (1+r)**periods_per_year - 1\n",
    "          - compounded=False → r * periods_per_year\n",
    "        \"\"\"\n",
    "        if compounded:\n",
    "            return (1.0 + s_returns) ** periods_per_year - 1.0\n",
    "        return s_returns * periods_per_year\n",
    "\n",
    "    # 🟣 ESPECÍFICAS MACRO ----------------------------------------------------\n",
    "\n",
    "    def ma_weeks_to_month(self, s_weekly_ma: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Convierte una media móvil semanal (p.ej., MA4) a frecuencia mensual\n",
    "        tomando el último valor disponible de cada mes.\n",
    "        Requiere que el índice sea datetime y esté en semanal.\n",
    "        \"\"\"\n",
    "        return s_weekly_ma.resample(\"M\").last()\n",
    "\n",
    "    def annualized_growth(self, s: pd.Series, window: int, periods_per_year: int, compounded: bool = True) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Crecimiento anualizado genérico desde una ventana de 'window' períodos:\n",
    "          - compounded=True  → (s / s.shift(window))**(periods_per_year/window) - 1\n",
    "          - compounded=False → (s/s.shift(window)-1) * (periods_per_year/window)\n",
    "        \"\"\"\n",
    "        ratio = s / s.shift(window)\n",
    "        if compounded:\n",
    "            return ratio ** (periods_per_year / window) - 1.0\n",
    "        return (ratio - 1.0) * (periods_per_year / window)\n",
    "\n",
    "    def flag_threshold(\n",
    "        self,\n",
    "        s: pd.Series,\n",
    "        threshold:int,\n",
    "        op: Literal[\"ge\", \"gt\", \"le\", \"lt\", \"eq\"] = \"ge\",\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Devuelve 0/1 si se cumple condición con el umbral.\n",
    "        op: ge (>=), gt (>), le (<=), lt (<), eq (==)\n",
    "        \"\"\"\n",
    "        ops = {\n",
    "            \"ge\": s >= threshold,\n",
    "            \"gt\": s > threshold,\n",
    "            \"le\": s <= threshold,\n",
    "            \"lt\": s < threshold,\n",
    "            \"eq\": s == threshold,\n",
    "        }\n",
    "        if op not in ops:\n",
    "            raise ValueError(\"op debe ser uno de {'ge','gt','le','lt','eq'}\")\n",
    "        return ops[op].astype(int)\n",
    "\n",
    "    def flag_persistence(\n",
    "        self,\n",
    "        cond_series: pd.Series,\n",
    "        n_periods: int,\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Marca 1 cuando una condición (serie booleana/0-1) se cumple N períodos seguidos.\n",
    "        \"\"\"\n",
    "        x = cond_series.astype(int)\n",
    "        return (x.rolling(n_periods).sum() >= n_periods).astype(int)\n",
    "\n",
    "        \n",
    "class LayerBuilder:\n",
    "    def __init__(self, loader:DataLoad, T:DataTransform):\n",
    "        self.loader = loader\n",
    "        self.T = T\n",
    "        self.step_registry = {}\n",
    "\n",
    "\n",
    "    def build(self, spec:LayerSpec) -> pd.DataFrame:\n",
    "        frames = []\n",
    "        for s in spec.series:\n",
    "            df_raw = self.loader.get_one(s.fred_id)\n",
    "            ser = df_raw[s.fred_id]\n",
    "            if s.units:ser = self.T.normalize_units(ser, s.units)\n",
    "            ser = self._to_target_freq(ser, s.freq_objetivo, s.agg)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484af10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulacion_rendimientos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
